{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd940d8-269e-4ea4-bf8d-a0841334dc21",
   "metadata": {},
   "source": [
    "# Vertex Pipelines: Qwik Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847446a3-4421-4cdf-b788-05ab59379497",
   "metadata": {},
   "source": [
    "## Task 4. Creating an end-to-end ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a87724-6a3d-4b3c-ad9d-ca6437e13f7f",
   "metadata": {},
   "source": [
    "It's time to build your first ML pipeline. In this pipeline, you'll use the UCI Machine Learning Dry Beans dataset, from: KOKLU, M. and OZKAN, I.A., (2020), \"Multiclass Classification of Dry Beans Using Computer Vision and Machine Learning Techniques.\"In Computers and Electronics in Agriculture, 174, 105507. DOI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308fa25-a903-4e9f-b284-e150c1a61781",
   "metadata": {},
   "source": [
    "This is a tabular dataset, and in your pipeline you'll use the dataset to train, evaluate, and deploy an AutoML model that classifies beans into one of 7 types based on their characteristics.\n",
    "\n",
    "This pipeline will:\n",
    "\n",
    "- Create a Dataset in Vertex AI\n",
    "- Train a tabular classification model with AutoML\n",
    "- Get evaluation metrics on this model\n",
    "- Based on the evaluation metrics, decide whether to deploy the model using conditional logic in Vertex Pipelines\n",
    "- Deploy the model to an endpoint using Vertex Prediction\n",
    "- Each of the steps outlined will be a component. Most of the pipeline steps will use pre-built components for Vertex AI services via the `google_cloud_pipeline_components` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e11953-c37a-4998-b52c-36fe2a7c93cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c3bccc-cca9-4913-9de4-bdcc4056d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform==1.0.0 in ./.local/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.22.2 in ./.local/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.0) (1.34.0)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.0) (1.43.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.0) (2.30.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.0) (21.3)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform==1.0.0) (1.19.8)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in ./.local/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in ./.local/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (2.3.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (2.26.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (1.42.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (1.42.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.0) (2.1.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.0) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2.0.0dev,>=1.32.0->google-cloud-aiplatform==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform==1.0.0) (3.0.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (4.2.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (59.4.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.0) (1.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.22.2->google-cloud-aiplatform==1.0.0) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.0.0) (2.21)\n",
      "Requirement already satisfied: kfp in ./.local/lib/python3.7/site-packages (1.8.19)\n",
      "Requirement already satisfied: google-cloud-pipeline-components==0.1.1 in ./.local/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform>=1.0.0 in ./.local/lib/python3.7/site-packages (from google-cloud-pipeline-components==0.1.1) (1.0.0)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in ./.local/lib/python3.7/site-packages (from kfp) (0.5.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in ./.local/lib/python3.7/site-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in ./.local/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in ./.local/lib/python3.7/site-packages (from kfp) (0.15)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from kfp) (4.0.1)\n",
      "Requirement already satisfied: jsonschema<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (4.2.1)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in ./.local/lib/python3.7/site-packages (from kfp) (0.7.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in ./.local/lib/python3.7/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.0.0)\n",
      "Requirement already satisfied: kubernetes<20,>=8.0.0 in ./.local/lib/python3.7/site-packages (from kfp) (19.15.0)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in ./.local/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in ./.local/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.43.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.0.3)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.2)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.16 in ./.local/lib/python3.7/site-packages (from kfp) (0.1.16)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.15.0)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in ./.local/lib/python3.7/site-packages (from kfp) (3.20.3)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in ./.local/lib/python3.7/site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in ./.local/lib/python3.7/site-packages (from kfp) (1.34.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.3.3)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in ./.local/lib/python3.7/site-packages (from kfp) (1.8.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.8.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.13.3)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in ./.local/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.59.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.2)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (59.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.0.0->google-cloud-pipeline-components==0.1.1) (1.19.8)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.0.0->google-cloud-pipeline-components==0.1.1) (21.3)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.0.0->google-cloud-pipeline-components==0.1.1) (2.30.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<3,>=1.20.0->kfp) (2.2.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<3,>=1.20.0->kfp) (2.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<5,>=3.0.1->kfp) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<5,>=3.0.1->kfp) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<5,>=3.0.1->kfp) (0.18.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<20,>=8.0.0->kfp) (1.2.1)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<20,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.42.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.42.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<3,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema<5,>=3.0.1->kfp) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.0.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<20,>=8.0.0->kfp) (3.1.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<3,>=1.20.0->kfp) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<3,>=1.20.0->kfp) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install {USER_FLAG} google-cloud-aiplatform==1.0.0 --upgrade\n",
    "!pip3 install {USER_FLAG} kfp google-cloud-pipeline-components==0.1.1 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09df923-f2f8-48d9-94af-524ddec64a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9d1edf-f920-470c-8f48-529df11605f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.19\n",
      "google_cloud_pipeline_components version: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc45f1c7-b664-459f-8cc4-17b77c502c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  qwiklabs-gcp-00-ad8666652f3f\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_ID = \"\"\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)\n",
    "    \n",
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd06be3-a2e7-49ba-9323-85d79f0468f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-00-ad8666652f3f-bucket-2/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fc7750-382b-44d1-a972-20f2fcd2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, ClassificationMetrics, Metrics, component)\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb376d57-f892-47d6-a61b-81a38599b169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://qwiklabs-gcp-00-ad8666652f3f-bucket/pipeline_root/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e1335-2816-4a93-b45f-5ecc5f33d48f",
   "metadata": {},
   "source": [
    "**Step 1: A custom component for model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e875e9c7-e52b-4d21-8b7e-47b53337c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"tables_eval_component.yaml\", # Optional: you can use this to load the component later\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classif_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,  # \"us-central1\",\n",
    "    api_endpoint: str,  # \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "    \"\"\"This function renders evaluation metrics for an AutoML Tabular classification model.\n",
    "    It retrieves the classification model evaluation generated by the AutoML Tabular training\n",
    "    process, does some parsing, and uses that info to render the ROC curve and confusion matrix\n",
    "    for the model. It also uses given metrics threshold information and compares that to the\n",
    "    evaluation results to determine whether the model is sufficiently accurate to deploy.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import logging\n",
    "    from google.cloud import aiplatform\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "        return (\n",
    "            evaluation.name,\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "    # Use the given metrics threshold(s) to determine whether the model is\n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\n",
    "                        \"{} < {}; returning False\".format(metrics_dict[k], v)\n",
    "                    )\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.uri.replace(\"aiplatform://v1/\", \"\")\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "        client, model_resource_path\n",
    "    )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f8a35c-3a56-415e-b337-dd6a44a1384b",
   "metadata": {},
   "source": [
    "**Step 2: Adding Google Cloud pre-built components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0549a6ec-9d54-49d0-afc8-2671f568e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-beans1680350077\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "DISPLAY_NAME = 'automl-beans{}'.format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8905be7-a23e-410c-acf5-9106887f8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"automl-tab-beans-training-v2\",\n",
    "                  pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_source: str = \"bq://aju-dev-demos.beans.beans1\",\n",
    "    display_name: str = DISPLAY_NAME,\n",
    "    project: str = PROJECT_ID,\n",
    "    gcp_region: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "    thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "):\n",
    "    dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "        project=project, display_name=display_name, bq_source=bq_source\n",
    "    )\n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=display_name,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        budget_milli_node_hours=1000,\n",
    "        column_transformations=[\n",
    "            {\"numeric\": {\"column_name\": \"Area\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Perimeter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MajorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"MinorAxisLength\"}},\n",
    "            {\"numeric\": {\"column_name\": \"AspectRation\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Eccentricity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ConvexArea\"}},\n",
    "            {\"numeric\": {\"column_name\": \"EquivDiameter\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Extent\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Solidity\"}},\n",
    "            {\"numeric\": {\"column_name\": \"roundness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"Compactness\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor1\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor2\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor3\"}},\n",
    "            {\"numeric\": {\"column_name\": \"ShapeFactor4\"}},\n",
    "            {\"categorical\": {\"column_name\": \"Class\"}},\n",
    "        ],\n",
    "        dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "        target_column=\"Class\",\n",
    "    )\n",
    "    model_eval_task = classif_model_eval_metrics(\n",
    "        project,\n",
    "        gcp_region,\n",
    "        api_endpoint,\n",
    "        thresholds_dict_str,\n",
    "        training_op.outputs[\"model\"],\n",
    "    )\n",
    "    with dsl.Condition(\n",
    "        model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "        deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "            model=training_op.outputs[\"model\"],\n",
    "            project=project,\n",
    "            machine_type=\"n1-standard-4\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ff4c4-7e41-49f0-8afd-2a275a9d34b7",
   "metadata": {},
   "source": [
    "What's happening in this code:\n",
    "\n",
    "First, just as in the previous pipeline, you define the input parameters this pipeline takes. You need to set these manually since they don't depend on the output of other steps in the pipeline.\n",
    "\n",
    "The rest of the pipeline uses a few pre-built components for interacting with Vertex AI services:\n",
    "\n",
    "- `TabularDatasetCreateOp` creates a tabular dataset in Vertex AI given a dataset source either in Cloud Storage or BigQuery. In this pipeline, you're passing the data via a BigQuery table URL.\n",
    "- `AutoMLTabularTrainingJobRunOp` kicks off an AutoML training job for a tabular dataset. You pass a few configuration parameters to this component, including the model type (in this case, classification), some data on the columns, how long you'd like to run training for, and a pointer to the dataset. Notice that to pass in the dataset to this component, you're providing the output of the previous component via dataset_create_op.outputs[\"dataset\"] .\n",
    "- `ModelDeployOp` deploys a given model to an endpoint in Vertex AI. There are additional configuration options available, but here you're providing the endpoint machine type, project, and model you'd like to deploy. You're passing in the model by accessing the outputs of the training step in your pipeline.\n",
    "\n",
    "This pipeline also makes use of **conditional logic**, a feature of Vertex Pipelines that lets you define a condition, along with different branches based on the result of that condition. Remember that when you defined the pipeline you passed a `thresholds_dict_str` parameter. This is the accuracy threshold you're using to determine whether to deploy your model to an endpoint. To implement this, make use of the Condition class from the KFP SDK. The condition passed in is the output of the custom eval component you defined earlier in this lab. If this condition is true, the pipeline will continue to execute the `deploy_op` component. If accuracy doesn't meet the predefined threshold, the pipeline will stop here and won't deploy a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47164f0-66ce-4ba8-a475-3db5f4e318d6",
   "metadata": {},
   "source": [
    "**Step 3: Compile and run the end-to-end ML pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06666d16-4b00-4fbd-9cb2-8dd2cccb6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"tab_classif_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ddb9a9-deb3-4bed-82ca-90e4c210f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e67f6260-5057-4ccf-ba5a-af7e86e30039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/automl-tab-beans-training-v2-20230401115458?project=qwiklabs-gcp-00-ad8666652f3f\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    \"tab_classif_pipeline.json\", pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"project\": PROJECT_ID,\n",
    "                      \"display_name\": DISPLAY_NAME}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9adefd0-1de1-47e3-a123-442a346e0c43",
   "metadata": {},
   "source": [
    "Click on the link shown after running the cell above to see your pipeline in the console. This pipeline will take a little over an hour to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68087cf1-ea26-4bac-be9e-7a534f15c833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
