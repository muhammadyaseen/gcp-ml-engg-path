{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Structured data prediction using Vertex AI Platform\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Create a BigQuery Dataset and Google Cloud Storage Bucket \n",
    "2. Export from BigQuery to CSVs in GCS\n",
    "3. Training on Cloud AI Platform\n",
    "4. Deploy trained model\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you train, evaluate, and deploy a machine learning model to predict a baby's weight.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nny3m465gKkY"
   },
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery==2.26.0\n",
      "  Downloading google_cloud_bigquery-2.26.0-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0dev,>=1.38.1 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (1.48.1)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.29.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (1.34.0)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (1.22.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (2.5.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (23.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (3.19.6)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-bigquery==2.26.0) (2.28.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (1.57.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (1.35.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (1.48.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.9/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery==2.26.0) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/lib/python3.9/site-packages (from grpcio<2.0dev,>=1.38.1->google-cloud-bigquery==2.26.0) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery==2.26.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery==2.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery==2.26.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-bigquery==2.26.0) (2022.12.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (67.7.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.29.0->google-cloud-bigquery==2.26.0) (0.4.8)\n",
      "Installing collected packages: google-cloud-bigquery\n",
      "Successfully installed google-cloud-bigquery-2.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user google-cloud-bigquery==2.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Restart your kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly ignore the deprecation warnings and incompatibility errors related to google-cloud-storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "## Set up environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set environment variables so that we can use them throughout the entire notebook. We will be using our project name for our bucket, so you only need to change your project and region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# change these to try this notebook out\n",
    "BUCKET = 'my-vai-project-quicklab' # Replace with the your bucket name\n",
    "PROJECT = 'qwiklabs-gcp-01-369fd887fdb3' # Replace with your project-id\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"TFVERSION\"] = \"2.6\"\n",
    "os.environ[\"PYTHONVERSION\"] = \"3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current GCP Project Name is: qwiklabs-gcp-01-369fd887fdb3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is: \"$PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0-vOB4y2BJM"
   },
   "source": [
    "## The source dataset\n",
    "\n",
    "Our dataset is hosted in [BigQuery](https://cloud.google.com/bigquery/). The CDC's Natality data has details on US births from 1969 to 2008 and is a publically available dataset, meaning anyone with a GCP account has access. Click [here](https://console.cloud.google.com/bigquery?project=bigquery-public-data&p=publicdata&d=samples&t=natality&page=table) to access the dataset.\n",
    "\n",
    "The natality dataset is relatively large at almost 138 million rows and 31 columns, but simple to understand. `weight_pounds` is the target, the continuous value we’ll train a model to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BigQuery Dataset and Google Cloud Storage Bucket \n",
    "\n",
    "A BigQuery dataset is a container for tables, views, and models built with BigQuery ML. Let's create one called __babyweight__. We'll do the same for a GCS bucket for our project too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/google-cloud-sdk/platform/bq/bq.py:42: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "W0613 14:09:27.215956 140381891229504 bigquery_client.py:731] There is no apilog flag so non-critical logging is disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BigQuery dataset titled: babyweight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/google-cloud-sdk/platform/bq/bq.py:42: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "W0613 14:09:29.005941 139651388241728 bigquery_client.py:731] There is no apilog flag so non-critical logging is disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'qwiklabs-gcp-01-369fd887fdb3:babyweight' successfully created.\n",
      "Here are your current datasets:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/google-cloud-sdk/platform/bq/bq.py:42: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "W0613 14:09:31.488947 140559469012800 bigquery_client.py:731] There is no apilog flag so non-critical logging is disabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  datasetId   \n",
      " ------------ \n",
      "  babyweight  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grep: /: Is a directory\n",
      "Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new GCS bucket.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://my-vai-project-quicklab/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'my-vai-project-quicklab' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are your current buckets:\n",
      "gs://my-vai-project-quicklab/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Create a BigQuery dataset for babyweight if it doesn't exist\n",
    "datasetexists=$(bq ls -d | grep -w babyweight)\n",
    "\n",
    "if [ -n \"$datasetexists\" ]; then\n",
    "    echo -e \"BigQuery dataset already exists, let's not recreate it.\"\n",
    "\n",
    "else\n",
    "    echo \"Creating BigQuery dataset titled: babyweight\"\n",
    "    \n",
    "    bq --location=US mk --dataset \\\n",
    "        --description \"Babyweight\" \\\n",
    "        $PROJECT:babyweight\n",
    "    echo \"Here are your current datasets:\"\n",
    "    bq ls\n",
    "fi\n",
    "    \n",
    "## Create GCS bucket if it doesn't exist already...\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "    echo -e \"Bucket exists, let's not recreate it.\"\n",
    "    \n",
    "else\n",
    "    echo \"Creating a new GCS bucket.\"\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "    echo \"Here are your current buckets:\"\n",
    "    gsutil ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2TuS1s9vREL"
   },
   "source": [
    "## Create the training and evaluation data tables\n",
    "\n",
    "Since there is already a publicly available dataset, we can simply create the training and evaluation data tables using this raw input data. First we are going to create a subset of the data limiting our columns to `weight_pounds`, `is_male`, `mother_age`, `plurality`, and `gestation_weeks` as well as some simple filtering and a column to hash on for repeatable splitting.\n",
    "\n",
    "* Note:  The dataset in the create table code below is the one created previously, e.g. \"babyweight\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and filter dataset\n",
    "\n",
    "We have some preprocessing and filtering we would like to do to get our data in the right format for training.\n",
    "\n",
    "Preprocessing:\n",
    "* Cast `is_male` from `BOOL` to `STRING`\n",
    "* Cast `plurality` from `INTEGER` to `STRING` where `[1, 2, 3, 4, 5]` becomes `[\"Single(1)\", \"Twins(2)\", \"Triplets(3)\", \"Quadruplets(4)\", \"Quintuplets(5)\"]`\n",
    "* Add `hashcolumn` hashing on `year` and `month`\n",
    "\n",
    "Filtering:\n",
    "* Only want data for years later than `2000`\n",
    "* Only want baby weights greater than `0`\n",
    "* Only want mothers whose age is greater than `0`\n",
    "* Only want plurality to be greater than `0`\n",
    "* Only want the number of weeks of gestation to be greater than `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.01s: 100%|██████████| 3/3 [00:00<00:00, 1007.12query/s]                        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_data AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    CAST(is_male AS STRING) AS is_male,\n",
    "    mother_age,\n",
    "    CASE\n",
    "        WHEN plurality = 1 THEN \"Single(1)\"\n",
    "        WHEN plurality = 2 THEN \"Twins(2)\"\n",
    "        WHEN plurality = 3 THEN \"Triplets(3)\"\n",
    "        WHEN plurality = 4 THEN \"Quadruplets(4)\"\n",
    "        WHEN plurality = 5 THEN \"Quintuplets(5)\"\n",
    "    END AS plurality,\n",
    "    gestation_weeks,\n",
    "    FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "            CAST(year AS STRING),\n",
    "            CAST(month AS STRING)\n",
    "        )\n",
    "    ) AS hashmonth\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE\n",
    "    year > 2000\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND plurality > 0\n",
    "    AND gestation_weeks > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment dataset to simulate missing data\n",
    "\n",
    "Now we want to augment our dataset with our simulated babyweight data by setting all gender information to `Unknown` and setting plurality of all non-single births to `Multiple(2+)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 2/2 [00:00<00:00, 692.93query/s]                         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_augmented_data AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    hashmonth\n",
    "FROM\n",
    "    babyweight.babyweight_data\n",
    "UNION ALL\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    \"Unknown\" AS is_male,\n",
    "    mother_age,\n",
    "    CASE\n",
    "        WHEN plurality = \"Single(1)\" THEN plurality\n",
    "        ELSE \"Multiple(2+)\"\n",
    "    END AS plurality,\n",
    "    gestation_weeks,\n",
    "    hashmonth\n",
    "FROM\n",
    "    babyweight.babyweight_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split augmented dataset into train and eval sets\n",
    "\n",
    "Using `hashmonth`, apply a module to get approximately a 75/25 train-eval split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split augmented dataset into train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CMNRractvREL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 3/3 [00:00<00:00, 1080.82query/s]                        \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_data_train AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks\n",
    "FROM\n",
    "    babyweight.babyweight_augmented_data\n",
    "WHERE\n",
    "    ABS(MOD(hashmonth, 4)) < 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split augmented dataset into eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 3/3 [00:00<00:00, 911.74query/s]                         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE OR REPLACE TABLE\n",
    "    babyweight.babyweight_data_eval AS\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks\n",
    "FROM\n",
    "    babyweight.babyweight_augmented_data\n",
    "WHERE\n",
    "    ABS(MOD(hashmonth, 4)) = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clnaaqQsXkwC"
   },
   "source": [
    "## Verify table creation\n",
    "\n",
    "Verify that you created the dataset and training data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 334.69query/s]                          \n",
      "Downloading: 0rows [00:00, ?rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [weight_pounds, is_male, mother_age, plurality, gestation_weeks]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- LIMIT 0 is a free query; this allows us to check that the table exists.\n",
    "SELECT * FROM babyweight.babyweight_data_train\n",
    "LIMIT 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 211.20query/s]                          \n",
      "Downloading: 0rows [00:00, ?rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [weight_pounds, is_male, mother_age, plurality, gestation_weeks]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "-- LIMIT 0 is a free query; this allows us to check that the table exists.\n",
    "SELECT * FROM babyweight.babyweight_data_eval\n",
    "LIMIT 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export from BigQuery to CSVs in GCS\n",
    "\n",
    "Use BigQuery Python API to export our train and eval tables to Google Cloud Storage in the CSV format to be used later for TensorFlow/Keras training. We'll want to use the dataset we've been using above as well as repeat the process for both training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported qwiklabs-gcp-01-369fd887fdb3:babyweight.babyweight_data_train to gs://my-vai-project-quicklab/babyweight/data/train*.csv\n",
      "Exported qwiklabs-gcp-01-369fd887fdb3:babyweight.babyweight_data_eval to gs://my-vai-project-quicklab/babyweight/data/eval*.csv\n"
     ]
    }
   ],
   "source": [
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client()\n",
    "\n",
    "dataset_name = \"babyweight\"\n",
    "\n",
    "# Create dataset reference object\n",
    "dataset_ref = client.dataset(\n",
    "    dataset_id=dataset_name, project=client.project)\n",
    "\n",
    "# Export both train and eval tables\n",
    "for step in [\"train\", \"eval\"]:\n",
    "    destination_uri = os.path.join(\n",
    "        \"gs://\", BUCKET, dataset_name, \"data\", \"{}*.csv\".format(step))\n",
    "    table_name = \"babyweight_data_{}\".format(step)\n",
    "    table_ref = dataset_ref.table(table_name)\n",
    "    extract_job = client.extract_table(\n",
    "        table_ref,\n",
    "        destination_uri,\n",
    "        # Location must match that of the source table.\n",
    "        location=\"US\",\n",
    "    )  # API request\n",
    "    extract_job.result()  # Waits for job to complete.\n",
    "\n",
    "    print(\"Exported {}:{}.{} to {}\".format(\n",
    "        client.project, dataset_name, table_name, destination_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify CSV creation\n",
    "\n",
    "Verify that we correctly created the CSV files in our bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000000.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000001.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000002.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000003.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000004.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000005.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000006.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000007.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000008.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000009.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000010.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000011.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000012.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000013.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000014.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000015.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000016.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000017.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000018.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000019.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000020.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000021.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000000.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000001.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000002.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000003.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000004.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000005.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000006.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000007.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000008.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000009.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000010.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000011.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000012.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000013.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000014.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000015.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000016.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000017.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000018.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000019.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000020.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000021.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000022.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000023.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000024.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000025.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000026.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000027.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000028.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000029.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000030.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000031.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000032.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000033.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000034.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000035.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000036.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000037.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000038.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000039.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000040.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000041.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000042.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000043.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000044.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000045.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000046.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000047.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000048.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000049.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000050.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000051.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000052.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000053.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000054.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000055.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000056.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000057.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000058.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000059.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000060.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000061.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000062.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000063.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000064.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000065.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000066.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000067.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000068.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000069.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000070.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000071.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000072.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000073.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000074.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000075.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000076.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000077.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000078.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000079.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000080.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000081.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000082.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000083.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000084.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/data/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data exists\n",
    "\n",
    "Verify that you previously created CSV files we'll be using for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-vai-project-quicklab/babyweight/data/eval000000000000.csv\n",
      "gs://my-vai-project-quicklab/babyweight/data/train000000000000.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/babyweight/data/*000000000000.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Cloud AI Platform\n",
    "\n",
    "Now that we see everything is working locally, it's time to train on the cloud! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit to the Cloud we use [`gcloud ai-platform jobs submit training [jobname]`](https://cloud.google.com/sdk/gcloud/reference/ml-engine/jobs/submit/training) and simply specify some additional parameters for AI Platform Training Service:\n",
    "- jobname: A unique identifier for the Cloud job. We usually append system time to ensure uniqueness\n",
    "- job-dir: A GCS location to upload the Python package to\n",
    "- runtime-version: Version of TF to use.\n",
    "- python-version: Version of Python to use.\n",
    "- region: Cloud region to train in. See [here](https://cloud.google.com/ml-engine/docs/tensorflow/regions) for supported AI Platform Training Service regions\n",
    "\n",
    "Below the `-- \\` we add in the arguments for our `task.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job [babyweight_230613_142301] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe babyweight_230613_142301\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs babyweight_230613_142301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: babyweight_230613_142301\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/babyweight/trained_model\n",
    "JOBID=babyweight_$(date -u +%y%m%d_%H%M%S)\n",
    "\n",
    "gcloud ai-platform jobs submit training ${JOBID} \\\n",
    "    --region=${REGION} \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=$(pwd)/babyweight/trainer \\\n",
    "    --job-dir=${OUTDIR} \\\n",
    "    --staging-bucket=gs://${BUCKET} \\\n",
    "    --master-machine-type=n1-standard-8 \\\n",
    "    --scale-tier=CUSTOM \\\n",
    "    --runtime-version=${TFVERSION} \\\n",
    "    --python-version=${PYTHONVERSION} \\\n",
    "    -- \\\n",
    "    --train_data_path=gs://${BUCKET}/babyweight/data/train*.csv \\\n",
    "    --eval_data_path=gs://${BUCKET}/babyweight/data/eval*.csv \\\n",
    "    --output_dir=${OUTDIR} \\\n",
    "    --num_epochs=10 \\\n",
    "    --train_examples=10000 \\\n",
    "    --eval_steps=100 \\\n",
    "    --batch_size=32 \\\n",
    "    --nembeds=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\t2023-06-13 14:23:04 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2023-06-13 14:23:19 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2023-06-13 14:23:19 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2023-06-13 14:23:19 +0000\tservice\t\tJob babyweight_230613_142301 is queued.\n",
      "INFO\t2023-06-13 14:23:21 +0000\tservice\t\tWaiting for training program to start.\n",
      "NOTICE\t2023-06-13 14:25:01 +0000\tmaster-replica-0.gcsfuse\t\tOpening GCS connection...\n",
      "NOTICE\t2023-06-13 14:25:01 +0000\tmaster-replica-0.gcsfuse\t\tMounting file system \"gcsfuse\"...\n",
      "NOTICE\t2023-06-13 14:25:01 +0000\tmaster-replica-0.gcsfuse\t\tFile system has been successfully mounted.\n",
      "INFO\t2023-06-13 14:26:52 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"chief\": [\"127.0.0.1:2222\"]} --task={\"type\": \"chief\", \"index\": 0} --job={  \"scale_tier\": \"CUSTOM\",  \"master_type\": \"n1-standard-8\",  \"package_uris\": [\"gs://my-vai-project-quicklab/babyweight_230613_142301/294e7a1698a2573b51c787270464db4119fb913c820ba855842fc3942105f6c5/babyweight-0.1.tar.gz\"],  \"python_module\": \"trainer.task\",  \"args\": [\"--train_data_path\\u003dgs://my-vai-project-quicklab/babyweight/data/train*.csv\", \"--eval_data_path\\u003dgs://my-vai-project-quicklab/babyweight/data/eval*.csv\", \"--output_dir\\u003dgs://my-vai-project-quicklab/babyweight/trained_model\", \"--num_epochs\\u003d10\", \"--train_examples\\u003d10000\", \"--eval_steps\\u003d100\", \"--batch_size\\u003d32\", \"--nembeds\\u003d8\"],  \"region\": \"us-central1\",  \"runtime_version\": \"2.6\",  \"job_dir\": \"gs://my-vai-project-quicklab/babyweight/trained_model\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.7\"}\n",
      "INFO\t2023-06-13 14:27:00 +0000\tmaster-replica-0\t\tRunning module trainer.task.\n",
      "INFO\t2023-06-13 14:27:00 +0000\tmaster-replica-0\t\tDownloading the package: gs://my-vai-project-quicklab/babyweight_230613_142301/294e7a1698a2573b51c787270464db4119fb913c820ba855842fc3942105f6c5/babyweight-0.1.tar.gz\n",
      "INFO\t2023-06-13 14:27:00 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://my-vai-project-quicklab/babyweight_230613_142301/294e7a1698a2573b51c787270464db4119fb913c820ba855842fc3942105f6c5/babyweight-0.1.tar.gz babyweight-0.1.tar.gz\n",
      "ERROR\t2023-06-13 14:27:00 +0000\tmaster-replica-0\t\tError in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "ERROR\t2023-06-13 14:27:00 +0000\tmaster-replica-0\t\tModuleNotFoundError: No module named 'pythonjsonlogger'\n",
      "ERROR\t2023-06-13 14:27:01 +0000\tmaster-replica-0\t\tError in sitecustomize; set PYTHONVERBOSE for traceback:\n",
      "ERROR\t2023-06-13 14:27:01 +0000\tmaster-replica-0\t\tModuleNotFoundError: No module named 'pythonjsonlogger'\n",
      "INFO\t2023-06-13 14:27:02 +0000\tmaster-replica-0\t\tInstalling the package: gs://my-vai-project-quicklab/babyweight_230613_142301/294e7a1698a2573b51c787270464db4119fb913c820ba855842fc3942105f6c5/babyweight-0.1.tar.gz\n",
      "INFO\t2023-06-13 14:27:02 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps babyweight-0.1.tar.gz\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\tProcessing ./babyweight-0.1.tar.gz\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\t  Preparing metadata (setup.py): started\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\trunning egg_info\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\tcreating /tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\twriting /tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info/PKG-INFO\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\twriting dependency_links to /tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info/dependency_links.txt\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\twriting top-level names to /tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info/top_level.txt\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\twriting manifest file '/tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\treading manifest file '/tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\twriting manifest file '/tmp/pip-pip-egg-info-o12_rwuf/babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\t  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: babyweight\n",
      "INFO\t2023-06-13 14:27:03 +0000\tmaster-replica-0\t\t  Building wheel for babyweight (setup.py): started\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning bdist_wheel\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning build\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning build_py\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build/lib\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcopying trainer/model.py -> build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcopying trainer/task.py -> build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcopying trainer/__init__.py -> build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning egg_info\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating babyweight.egg-info\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\twriting babyweight.egg-info/PKG-INFO\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\twriting dependency_links to babyweight.egg-info/dependency_links.txt\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\twriting top-level names to babyweight.egg-info/top_level.txt\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\twriting manifest file 'babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\treading manifest file 'babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\twriting manifest file 'babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tinstalling to build/bdist.linux-x86_64/wheel\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning install\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning install_lib\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64/wheel\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcopying build/lib/trainer/model.py -> build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcopying build/lib/trainer/task.py -> build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcopying build/lib/trainer/__init__.py -> build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning install_egg_info\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tCopying babyweight.egg-info to build/bdist.linux-x86_64/wheel/babyweight-0.1-py3.7.egg-info\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\trunning install_scripts\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64/wheel/babyweight-0.1.dist-info/WHEEL\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tcreating '/tmp/pip-wheel-efzdx9do/babyweight-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'trainer/model.py'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'trainer/task.py'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/METADATA'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/WHEEL'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/top_level.txt'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/RECORD'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tremoving build/bdist.linux-x86_64/wheel\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\t  Building wheel for babyweight (setup.py): finished with status 'done'\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\t  Created wheel for babyweight: filename=babyweight-0.1-py3-none-any.whl size=6467 sha256=2a4015faadfcd2ebcfcf23d8db61ac3be2c60f09ac4479ef5260f2b256ca55b2\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/6c/d0/f0/0f474de29cf23d1a356e7be1ca1195a7dcacd493479d8b10b0\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tSuccessfully built babyweight\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tInstalling collected packages: babyweight\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tSuccessfully installed babyweight-0.1\n",
      "ERROR\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "INFO\t2023-06-13 14:27:04 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user babyweight-0.1.tar.gz\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\tProcessing ./babyweight-0.1.tar.gz\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\t  Preparing metadata (setup.py): started\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\trunning egg_info\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\tcreating /tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\twriting /tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info/PKG-INFO\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\twriting dependency_links to /tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info/dependency_links.txt\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\twriting top-level names to /tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info/top_level.txt\n",
      "INFO\t2023-06-13 14:27:05 +0000\tmaster-replica-0\t\twriting manifest file '/tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\treading manifest file '/tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\twriting manifest file '/tmp/pip-pip-egg-info-fv0elsfk/babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\t  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: babyweight\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\t  Building wheel for babyweight (setup.py): started\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning bdist_wheel\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning build\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning build_py\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build/lib\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcopying trainer/model.py -> build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcopying trainer/task.py -> build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcopying trainer/__init__.py -> build/lib/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning egg_info\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating babyweight.egg-info\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\twriting babyweight.egg-info/PKG-INFO\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\twriting dependency_links to babyweight.egg-info/dependency_links.txt\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\twriting top-level names to babyweight.egg-info/top_level.txt\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\twriting manifest file 'babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\treading manifest file 'babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\twriting manifest file 'babyweight.egg-info/SOURCES.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tinstalling to build/bdist.linux-x86_64/wheel\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning install\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning install_lib\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64/wheel\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcopying build/lib/trainer/model.py -> build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcopying build/lib/trainer/task.py -> build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcopying build/lib/trainer/__init__.py -> build/bdist.linux-x86_64/wheel/trainer\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning install_egg_info\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tCopying babyweight.egg-info to build/bdist.linux-x86_64/wheel/babyweight-0.1-py3.7.egg-info\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\trunning install_scripts\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating build/bdist.linux-x86_64/wheel/babyweight-0.1.dist-info/WHEEL\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tcreating '/tmp/pip-wheel-x8sd5fp7/babyweight-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'trainer/__init__.py'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'trainer/model.py'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'trainer/task.py'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/METADATA'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/WHEEL'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/top_level.txt'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tadding 'babyweight-0.1.dist-info/RECORD'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tremoving build/bdist.linux-x86_64/wheel\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\t  Building wheel for babyweight (setup.py): finished with status 'done'\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\t  Created wheel for babyweight: filename=babyweight-0.1-py3-none-any.whl size=6467 sha256=9cda856ef99ea55f240489843e2ebb620328efbfa52730334549b5815d198b92\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/6c/d0/f0/0f474de29cf23d1a356e7be1ca1195a7dcacd493479d8b10b0\n",
      "INFO\t2023-06-13 14:27:06 +0000\tmaster-replica-0\t\tSuccessfully built babyweight\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\tInstalling collected packages: babyweight\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\t  Attempting uninstall: babyweight\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\t    Found existing installation: babyweight 0.1\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\t    Uninstalling babyweight-0.1:\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\t      Successfully uninstalled babyweight-0.1\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\tSuccessfully installed babyweight-0.1\n",
      "ERROR\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\tWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "INFO\t2023-06-13 14:27:09 +0000\tmaster-replica-0\t\tRunning command: python3 -m trainer.task --train_data_path=gs://my-vai-project-quicklab/babyweight/data/train*.csv --eval_data_path=gs://my-vai-project-quicklab/babyweight/data/eval*.csv --output_dir=gs://my-vai-project-quicklab/babyweight/trained_model --num_epochs=10 --train_examples=10000 --eval_steps=100 --batch_size=32 --nembeds=8 --job-dir gs://my-vai-project-quicklab/babyweight/trained_model\n",
      "INFO\t2023-06-13 14:27:15 +0000\tmaster-replica-0\t\tNone of the MLIR Optimization Passes are enabled (registered 2)\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tHere is our Wide-and-Deep architecture so far:\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tModel: \"model\"\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tLayer (type)                    Output Shape         Param #     Connected to                     \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t==================================================================================================\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tgestation_weeks (InputLayer)    [(None,)]            0                                            \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tis_male (InputLayer)            [(None,)]            0                                            \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tmother_age (InputLayer)         [(None,)]            0                                            \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tplurality (InputLayer)          [(None,)]            0                                            \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tdeep_inputs (DenseFeatures)     (None, 10)           8000        gestation_weeks[0][0]            \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 is_male[0][0]                    \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 mother_age[0][0]                 \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 plurality[0][0]                  \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tdnn_1 (Dense)                   (None, 128)          1408        deep_inputs[0][0]                \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tdnn_2 (Dense)                   (None, 32)           4128        dnn_1[0][0]                      \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\twide_inputs (DenseFeatures)     (None, 71)           0           gestation_weeks[0][0]            \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 is_male[0][0]                    \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 mother_age[0][0]                 \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 plurality[0][0]                  \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tdnn_3 (Dense)                   (None, 4)            132         dnn_2[0][0]                      \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tlinear (Dense)                  (None, 10)           720         wide_inputs[0][0]                \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tboth (Concatenate)              (None, 14)           0           dnn_3[0][0]                      \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t                                                                 linear[0][0]                     \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tweight (Dense)                  (None, 1)            15          both[0][0]                       \n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t==================================================================================================\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tTotal params: 14,403\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tTrainable params: 14,403\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tNon-trainable params: 0\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t__________________________________________________________________________________________________\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tNone\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tmode = train\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tmode = eval\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\tEpoch 1/10\n",
      "INFO\t2023-06-13 14:28:00 +0000\tmaster-replica-0\t\t31250/31250 - 47s - loss: 1.1030 - rmse: 1.0320 - mse: 1.1030 - val_loss: 1.0480 - val_rmse: 1.0233 - val_mse: 1.0480\n",
      "INFO\t2023-06-13 14:28:48 +0000\tmaster-replica-0\t\tEpoch 00001: saving model to gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/babyweight\n",
      "INFO\t2023-06-13 14:28:48 +0000\tmaster-replica-0\t\tEpoch 2/10\n",
      "INFO\t2023-06-13 14:28:48 +0000\tmaster-replica-0\t\t31250/31250 - 44s - loss: 1.0830 - rmse: 1.0291 - mse: 1.0830 - val_loss: 1.0416 - val_rmse: 1.0202 - val_mse: 1.0416\n",
      "INFO\t2023-06-13 14:29:35 +0000\tmaster-replica-0\t\tEpoch 00002: saving model to gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/babyweight\n",
      "INFO\t2023-06-13 14:29:35 +0000\tmaster-replica-0\t\tEpoch 3/10\n",
      "INFO\t2023-06-13 14:29:35 +0000\tmaster-replica-0\t\t31250/31250 - 44s - loss: 1.0750 - rmse: 1.0256 - mse: 1.0750 - val_loss: 1.0530 - val_rmse: 1.0258 - val_mse: 1.0530\n",
      "INFO\t2023-06-13 14:30:22 +0000\tmaster-replica-0\t\tEpoch 00003: saving model to gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/babyweight\n",
      "INFO\t2023-06-13 14:30:22 +0000\tmaster-replica-0\t\tEpoch 4/10\n",
      "INFO\t2023-06-13 14:30:22 +0000\tmaster-replica-0\t\t31250/31250 - 44s - loss: 1.0793 - rmse: 1.0275 - mse: 1.0793 - val_loss: 1.0418 - val_rmse: 1.0204 - val_mse: 1.0418\n",
      "INFO\t2023-06-13 14:31:09 +0000\tmaster-replica-0\t\tEpoch 5/10\n",
      "INFO\t2023-06-13 14:31:09 +0000\tmaster-replica-0\t\t31250/31250 - 44s - loss: 1.0814 - rmse: 1.0285 - mse: 1.0814 - val_loss: 1.0272 - val_rmse: 1.0131 - val_mse: 1.0272\n",
      "INFO\t2023-06-13 14:31:56 +0000\tmaster-replica-0\t\tEpoch 00005: saving model to gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/babyweight\n",
      "INFO\t2023-06-13 14:31:56 +0000\tmaster-replica-0\t\tEpoch 6/10\n",
      "INFO\t2023-06-13 14:31:56 +0000\tmaster-replica-0\t\t31250/31250 - 44s - loss: 1.0660 - rmse: 1.0212 - mse: 1.0660 - val_loss: 1.0367 - val_rmse: 1.0179 - val_mse: 1.0367\n",
      "INFO\t2023-06-13 14:32:42 +0000\tmaster-replica-0\t\tEpoch 00006: saving model to gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/babyweight\n",
      "INFO\t2023-06-13 14:32:42 +0000\tmaster-replica-0\t\tEpoch 7/10\n",
      "INFO\t2023-06-13 14:32:42 +0000\tmaster-replica-0\t\t31250/31250 - 43s - loss: 1.0722 - rmse: 1.0238 - mse: 1.0722 - val_loss: 1.0358 - val_rmse: 1.0173 - val_mse: 1.0358\n",
      "INFO\t2023-06-13 14:33:29 +0000\tmaster-replica-0\t\tEpoch 00007: saving model to gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/babyweight\n",
      "INFO\t2023-06-13 14:33:29 +0000\tmaster-replica-0\t\tEpoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Command killed by keyboard interrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gcloud ai-platform jobs stream-logs babyweight_230613_142301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training job should complete within 15 to 20 minutes. You do not need to wait for this training job to finish before moving forward in the notebook, but will need a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check our trained model files\n",
    "\n",
    "Let's check the directory structure of our outputs of our trained model in folder we exported. We'll want to deploy the saved_model.pb within the timestamped directory as well as the variable values in the variables folder. Therefore, we need the path of the timestamped directory so that everything within it can be found by Cloud AI Platform's model deployment service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-vai-project-quicklab/babyweight/trained_model/\n",
      "gs://my-vai-project-quicklab/babyweight/trained_model/20230613143505/\n",
      "gs://my-vai-project-quicklab/babyweight/trained_model/checkpoints/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "gsutil ls gs://${BUCKET}/babyweight/trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://my-vai-project-quicklab/babyweight/trained_model/20230613143505/\n",
      "gs://my-vai-project-quicklab/babyweight/trained_model/20230613143505/saved_model.pb\n",
      "gs://my-vai-project-quicklab/babyweight/trained_model/20230613143505/assets/\n",
      "gs://my-vai-project-quicklab/babyweight/trained_model/20230613143505/variables/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_LOCATION=$(gsutil ls -ld -- gs://${BUCKET}/babyweight/trained_model/2* \\\n",
    "                 | tail -1)\n",
    "gsutil ls ${MODEL_LOCATION}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy trained model\n",
    "\n",
    "Deploying the trained model to act as a REST web service is a simple gcloud call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [ai_platform/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set ai_platform/region global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying babyweight ml_on_gcp from gs://my-vai-project-quicklab/babyweight/trained_model/20230613143505/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Created ai platform model [projects/qwiklabs-gcp-01-369fd887fdb3/models/babyweight].\n",
      "Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......\n",
      "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"babyweight\"\n",
    "MODEL_VERSION=\"ml_on_gcp\"\n",
    "MODEL_LOCATION=$(gsutil ls -ld -- gs://${BUCKET}/babyweight/trained_model/2* \\\n",
    "                 | tail -1 | tr -d '[:space:]')\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION\"\n",
    "# gcloud ai-platform versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "# gcloud ai-platform models delete ${MODEL_NAME}\n",
    "gcloud ai-platform models create ${MODEL_NAME} --regions ${REGION}\n",
    "gcloud ai-platform versions create ${MODEL_VERSION} \\\n",
    "    --model=${MODEL_NAME} \\\n",
    "    --origin=${MODEL_LOCATION} \\\n",
    "    --runtime-version=2.6 \\\n",
    "    --python-version=3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
